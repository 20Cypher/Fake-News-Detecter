# -*- coding: utf-8 -*-
"""Fake_News_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yucmL-9qEoyDWV2wgO00uX7cIIrQK6xa
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report
import re
import string

data_fake = pd.read_csv("Fake.csv")
data_true = pd.read_csv("True.csv")

data_fake.head()

data_true.head()

data_fake["class"] = 0
data_true["class"] = 1

"""# Removing 10 data points for testing"""

data_fake.shape, data_true.shape

data_fake_manual_test = data_fake.tail(10)
for i in range(23480, 23470, -1):
  data_fake.drop([i], axis = 0, inplace = True)

data_true_manual_test = data_true.tail(10)
for i in range(21416, 21406, -1):
  data_true.drop([i], axis = 0, inplace = True)

data_fake.shape, data_true.shape

data_fake_manual_test["class"] = 0
data_true_manual_test["class"] = 1

data_true_manual_test.head()

"""# Merge true and false datasets and process the merged dataset

"""

data_merge = pd.concat([data_fake, data_true], axis = 0)

data = data_merge.drop(['title', 'subject', 'date'], axis = 1)

data.isnull().sum()

data = data.sample(frac = 1)

data.head()

data.reset_index(inplace = True)
data.drop(['index'], axis = 1, inplace = True)

data.head()

"""# Function to define text

This function is designed to clean and normalize text data by converting it to lowercase, removing specific patterns (such as URLs and HTML tags), replacing non-word characters with spaces, removing punctuation, and eliminating words containing digits.
"""

def wordopt(text):
    if isinstance(text, str):
        text = text.lower()
        text = re.sub('\[.*?\]', '', text)
        text = re.sub("\\W"," ", text)
        text = re.sub('https?://\S+|www\.\S+', '', text)
        text = re.sub('<.*?>+', '', text)
        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
        text = re.sub('\n', '', text)
        text = re.sub('\w*\d\w*', '', text)
        return text
    else:
        # If text is not a string, return it as is
        return text

data['text'] = data['text'].apply(wordopt)

x = data['text']
y = data['class']

x.head()

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25)

"""# Vectorization of text"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorization = TfidfVectorizer()
xv_train = vectorization.fit_transform(x_train)
xv_test = vectorization.transform(x_test)

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression

reg = LogisticRegression()
reg.fit(xv_train, y_train)

pred_lr = reg.predict(xv_test)

reg.score(xv_test, y_test)

print(classification_report(y_test, pred_lr))

# """# Decision Tree Classification"""

# from sklearn.tree import DecisionTreeClassifier

# dt = DecisionTreeClassifier()
# dt.fit(xv_train, y_train)

# pred_dt = dt.predict(xv_test)

# dt.score(xv_test, y_test)

# print(classification_report(y_test, pred_dt))

# """# Gradient Boosting Classifier"""

# from sklearn.ensemble import GradientBoostingClassifier

# gb = GradientBoostingClassifier(random_state=0)
# gb.fit(xv_train, y_train)

# pred_gb = gb.predict(xv_test)

# gb.score(xv_test, y_test)

# print(classification_report(y_test, pred_gb))

# """# Random Forest"""

# from sklearn.ensemble import RandomForestClassifier

# rf = RandomForestClassifier(random_state=0)
# rf.fit(xv_train, y_train)

# pred_rf = rf.predict(xv_test)

# rf.score(xv_test, y_test)

# print(classification_report(y_test, pred_rf))

def output_label(n):
  if n==0:
    return "Fake News"
  elif n==1:
    return "Not a Fake News"

def manual_testing(news):
  testing_news = {"text":[news]}
  new_def_test = pd.DataFrame(testing_news)
  new_def_test["text"] = new_def_test["text"].apply(wordopt)
  new_x_test = new_def_test["text"]
  new_xv_test = vectorization.transform(new_x_test)
  pred_lr = reg.predict(new_xv_test)
  # pred_dt = dt.predict(new_xv_test)
  # pred_gb = gb.predict(new_xv_test)
  # pred_rf = rf.predict(new_xv_test)

  return output_label(pred_lr[0])
  # return print("\n\nLogistic Regression Prediction: {} \nDecision Tree Prediction: {} \nGradient Boost Classifier Prediction: {} \nRandom Forest Prediction: {}".format(output_label(pred_lr[0]), output_label(pred_dt[0]), output_label(pred_gb[0]), output_label(pred_rf[0])))
